{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks with Data Augmentation using Keras\n",
    "\n",
    "In this tutorial I will be using Keras with TensorFlow as backend to calssify digits from the MNIST Dataset\n",
    "\n",
    "https://www.kaggle.com/moghazy/guide-to-cnns-with-data-augmentation-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "datapath = path[:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "import pandas as pd\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "K.set_image_data_format('channels_last') # Tensorflow's convention \n",
    "numpy.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## --- Load the data\n",
    "# Dataset of 56,000 28x28 grayscale images of the 10 digits, \n",
    "# each image has 784 features. This is because each image is 28Ã—28 pixels,\n",
    "# along with a test set of 14,000 images. \n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56000, 784)\n",
      "(56000,)\n",
      "(14000, 784)\n",
      "(14000,)\n"
     ]
    }
   ],
   "source": [
    "# Get training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2 , random_state=42)\n",
    "print(X_train.shape, y_train.shape,X_test.shape, y_test.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56000, 28, 28, 1)\n",
      "(14000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# We then reshape the samples according to TensorFlow convention \n",
    "# which we chosed previously using \"K.set_image_data_format('channels_last')\" \n",
    "# Here we have only one channel because we are using the image in grayscale not RGB. \n",
    "# samples,rows,columns,channels\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28 , 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28 , 1).astype('float32')\n",
    "print(X_train.shape,X_test.shape, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of training examples = 56000\n",
      "the number of classes = 10\n",
      "Dimention of images = 28 x 28  \n",
      "The number of occuranc of each class in the dataset = \n",
      "{0.0: 5554, 1.0: 6296, 2.0: 5590, 3.0: 5707, 4.0: 5496, 5.0: 5027, 6.0: 5469, 7.0: 5817, 8.0: 5434, 9.0: 5610}  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## --- Explore the data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"the number of training examples = %i\" % X_train.shape[0])\n",
    "print(\"the number of classes = %i\" % len(numpy.unique(y_train)))\n",
    "print(\"Dimention of images = {:d} x {:d}  \".format(X_train[1].shape[0],X_train[1].shape[1])  )\n",
    "\n",
    "#This line will allow us to know the number of occurrences of each specific class in the data\n",
    "unique, count= numpy.unique(y_train, return_counts=True)\n",
    "print(\"The number of occuranc of each class in the dataset = \\n%s \" % dict (zip(unique, count) ), \"\\n\" )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of image and labels: 56000 x 2\n",
      "Shape of one example of image_and_labels: 28 x 28 x 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a35ec5048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "images_and_labels = list(zip(X_train,  y_train))\n",
    "print(\"Shape of image and labels: {:d} x {:d}\".format(np.array(images_and_labels).shape[0],np.array(images_and_labels).shape[1]))\n",
    "print(\"Shape of one example of image_and_labels: {:d} x {:d} x {:d}\".format(np.array(images_and_labels[0][0]).shape[0], np.array(images_and_labels[0][0]).shape[1], np.array(images_and_labels[0][0]).shape[2]))\n",
    "for index, (image, label) in enumerate(images_and_labels[:12]):\n",
    "    plt.subplot(5, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image.squeeze(), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('label: %i' % label )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout,Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "\n",
    "# For the sequential model you just stack the layers and \n",
    "# only specify the image input dimensions in the first layer. \n",
    "\n",
    "# Our first layer will be a convolutional layer Conv2D() where we specify the number of feature maps\n",
    "\n",
    "model.add(Conv2D(40, kernel_size=5, padding=\"same\",input_shape=(28, 28, 1), activation = 'relu'))\n",
    "\n",
    "# We then add the max pooling layer (which is the most common kind of pooling) \n",
    "# with a kernel of dimensions 2 * 2 .\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets add the 2nd layer but this time we increase the feature maps .\n",
    "\n",
    "model.add(Conv2D(70, kernel_size=3, padding=\"same\", activation = 'relu'))\n",
    "model.add(Conv2D(500, kernel_size=3, padding=\"same\", activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(1024, kernel_size=3, padding=\"valid\", activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/iZbra1/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2880: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Users/iZbra1/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1344: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# Now we add a flatten layer that takes the output of the CNN and \n",
    "# flattens it and passes it as an input to the Dense Layers which passes it to the output layer. \n",
    "# Every dense layer contains 300 neurons except for the output layer. \n",
    "# We use Softmax with the output layer to output estimated probability vector for multi-class classification .\n",
    "\n",
    "from keras.layers.core import Activation\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=100, activation='relu'  ))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=100, activation='relu'  ))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=100, activation='relu'  ))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, ..., 1, 0, 0],\n",
       "        [0, 0, 0, ..., 1, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 1],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 1, ..., 0, 0, 0]], dtype=int32), 56000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have used categorical_crossentropy as the cost function \n",
    "# We are using adam optimizer which is one of the best gradient descent algorithms.\n",
    "# One hot encoding:\n",
    "y_train = np_utils.to_categorical(y_train).astype('int32')\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[1, 0],\n",
       "         [1, 0],\n",
       "         [1, 0],\n",
       "         ...,\n",
       "         [0, 1],\n",
       "         [1, 0],\n",
       "         [1, 0]],\n",
       " \n",
       "        [[1, 0],\n",
       "         [1, 0],\n",
       "         [1, 0],\n",
       "         ...,\n",
       "         [0, 1],\n",
       "         [1, 0],\n",
       "         [1, 0]],\n",
       " \n",
       "        [[1, 0],\n",
       "         [0, 1],\n",
       "         [1, 0],\n",
       "         ...,\n",
       "         [1, 0],\n",
       "         [1, 0],\n",
       "         [1, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1, 0],\n",
       "         [1, 0],\n",
       "         [1, 0],\n",
       "         ...,\n",
       "         [1, 0],\n",
       "         [1, 0],\n",
       "         [0, 1]],\n",
       " \n",
       "        [[0, 1],\n",
       "         [1, 0],\n",
       "         [1, 0],\n",
       "         ...,\n",
       "         [1, 0],\n",
       "         [1, 0],\n",
       "         [1, 0]],\n",
       " \n",
       "        [[1, 0],\n",
       "         [1, 0],\n",
       "         [0, 1],\n",
       "         ...,\n",
       "         [1, 0],\n",
       "         [1, 0],\n",
       "         [1, 0]]], dtype=int32), 56000)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Use ImageDataGenerator from keras to augment the images.\n",
    "# Centering the images, normalization, rotation, shifting, and flipping \n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Shifting...\n",
    "X_train = X_train.reshape(-1,28,28,1)\n",
    "X_test = X_test.reshape(-1,28,28,1)\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "X_train2 = numpy.array(X_train, copy=True) \n",
    "y_train2 = numpy.array(y_train, copy=True) \n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    )\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "print(type(X_train2))\n",
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating the old data with the augmented data\n",
    "result_x  = numpy.concatenate((X_train, X_train2), axis=0)\n",
    "result_y  = numpy.concatenate((y_train, y_train2), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time spent: 11h 43m !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "3200/1750 [======================================================] - 3651s 1s/step - loss: 0.1047 - acc: 0.9725\n",
      "Epoch 2/12\n",
      "3200/1750 [======================================================] - 3593s 1s/step - loss: 0.0739 - acc: 0.9822\n",
      "Epoch 3/12\n",
      "3200/1750 [======================================================] - 3123s 976ms/step - loss: 0.0620 - acc: 0.9850\n",
      "Epoch 4/12\n",
      "3200/1750 [======================================================] - 3207s 1s/step - loss: 0.0604 - acc: 0.9862\n",
      "Epoch 5/12\n",
      "3200/1750 [======================================================] - 3451s 1s/step - loss: 0.0495 - acc: 0.9882\n",
      "Epoch 6/12\n",
      "3200/1750 [======================================================] - 3454s 1s/step - loss: 0.0506 - acc: 0.9887\n",
      "Epoch 7/12\n",
      "3200/1750 [======================================================] - 3478s 1s/step - loss: 0.0510 - acc: 0.9890\n",
      "Epoch 8/12\n",
      "3200/1750 [======================================================] - 3895s 1s/step - loss: 0.0562 - acc: 0.9876\n",
      "Epoch 9/12\n",
      "3200/1750 [======================================================] - 4376s 1s/step - loss: 0.0471 - acc: 0.9895\n",
      "Epoch 10/12\n",
      "3200/1750 [======================================================] - 3258s 1s/step - loss: 0.0527 - acc: 0.9887\n",
      "Epoch 11/12\n",
      "3200/1750 [======================================================] - 3295s 1s/step - loss: 0.0489 - acc: 0.9897\n",
      "Epoch 12/12\n",
      "3200/1750 [======================================================] - 3429s 1s/step - loss: 0.0469 - acc: 0.9903\n",
      "Time spend: 42212.53016400337\n"
     ]
    }
   ],
   "source": [
    "# # fits the model on batches with real-time data augmentation:\n",
    "from time import time\n",
    "start = time()\n",
    "\n",
    "history = model.fit_generator(datagen.flow(result_x, result_y, batch_size=35),\n",
    "                    steps_per_epoch=len(X_train) / 32, epochs = 12)\n",
    "\n",
    "print('Time spend:', time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3b681160>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes ~ 2 min\n",
    "# model.fit(X_train, y_train, epochs= 32 , batch_size=200, validation_split = 0.2)\n",
    "scores = model.evaluate(X_test, y_test, verbose = 10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18328269741015746, 0.9881428571428571]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print ( scores )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/iZbra1/Documents/DS tools/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185.74328923225403 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      0\n",
       "4        5      3\n",
       "5        6      7\n",
       "6        7      0\n",
       "7        8      3\n",
       "8        9      0\n",
       "9       10      3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Takes 185 s\n",
    "start = time()\n",
    "test_set = (test.values).reshape(-1, 28, 28 , 1).astype('float32')\n",
    "\n",
    "res = model.predict(test_set)\n",
    "res = numpy.argmax(res,axis = 1)\n",
    "res = pd.Series(res, name=\"Label\")\n",
    "submission = pd.concat([pd.Series(range(1 ,28001) ,name = \"ImageId\"),   res],axis = 1)\n",
    "submission.to_csv(\"cnn_mnist_datagen.csv\",index=False)\n",
    "print(time()-start,'s')\n",
    "submission.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/iZbra1/Documents/DS tools/'\n",
    "os.chdir(path+'data/CNN_example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model weights are saved to HDF5 format. This is a grid format that is ideal for storing multi-dimensional arrays of numbers.\n",
    "# The model structure can be described and saved using two different formats: JSON and YAML.\n",
    "\n",
    "# serialize (architecture of) model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "os.listdir(path+'data/CNN_example')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To open model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/iZbra1/Documents/K2DS/Projects/book_cover_recommender/notebooks'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.json', 'cnn_mnist_datagen.csv', 'test.csv', 'model.h5']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(datapath+'DS tools/data/CNN_example/')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.models.Sequential at 0x1a36cfb6a0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      0\n",
       "4        5      3\n",
       "5        6      7\n",
       "6        7      0\n",
       "7        8      3\n",
       "8        9      0\n",
       "9       10      3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Takes 185 s\n",
    "\n",
    "test_set = (test.values).reshape(-1, 28, 28 , 1).astype('float32')\n",
    "test = pd.read_csv('test.csv')\n",
    "res = loaded_model.predict(test_set)\n",
    "res = numpy.argmax(res,axis = 1)\n",
    "res = pd.Series(res, name=\"Label\")\n",
    "submission = pd.concat([pd.Series(range(1 ,28001) ,name = \"ImageId\"),   res],axis = 1)\n",
    "submission.to_csv(\"cnn_mnist_datagen.csv\",index=False)\n",
    "\n",
    "submission.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
